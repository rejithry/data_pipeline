services:
  kafkabroker:
    image: apache/kafka-native
    ports:
      - "9092:9092"
    container_name: kafkabroker
    networks:
      - my-net
    environment:
      # Configure listeners for both docker and host communication
      KAFKA_LISTENERS: CONTROLLER://localhost:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: HOST://kafkabroker:9092,DOCKER://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,DOCKER:PLAINTEXT,HOST:PLAINTEXT

      # Settings required for KRaft mode
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9091

      # Listener to use for broker-to-broker communication
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER

      # Required for a single node cluster
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  spark_test:
    image: jupyter_notebook
    container_name: spark_test
    user: root
    command: start.sh jupyter notebook --NotebookApp.token=''
    networks:
      - my-net
    ports:
      - "50002:8888"
      - "4040:4040"
      - "7077:7077"
      - "8080:8080"
      - "10000:10000"
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 resourcemanager:8088 kafkabroker:9092 hive-metastore:9083"
    volumes:
      - ./notebooks/:/home/jovyan/work/
    restart: unless-stopped

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: unless-stopped
    networks:
      - my-net
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    restart: unless-stopped
    networks:
      - my-net
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env

  
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: unless-stopped
    networks:
      - my-net
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864"
    env_file:
      - ./hadoop.env

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: unless-stopped
    networks:
      - my-net
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864  resourcemanager:8088"
    env_file:
      - ./hadoop.env
  
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: unless-stopped
    networks:
      - my-net
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env

  client:
    image: client
    container_name: client
    restart: unless-stopped
    networks:
      - my-net

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    restart: unless-stopped
    networks:
      - my-net
    env_file:
      - ./hadoop.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    restart: unless-stopped
    container_name: hive-metastore-postgresql
    networks:
      - my-net
    ports:
      - "5432:5432"
    env_file:
      - ./hadoop.env

  postgres:
    image: postgres:14-bullseye
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: default
    ports:
      - "6999:5432" # Map host port 5432 to container port 5432
    volumes:
      - pgdata:/var/lib/postgresql/data # Persistent data storage
    networks:
      - my-net
    
  flink-jobmanager:
    image: apache/flink:latest # Use a specific version like 1.20-scala_2.12
    ports:
      - "8081:8081" # Exposes the Flink Web UI
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
    volumes:
      - flink_data:/tmp/flink-checkpoints
    networks:
      - my-net

      
  flink-taskmanager:
    image: apache/flink:latest
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2 
    volumes:
      - flink_data:/tmp/flink-checkpoints
    networks:
      - my-net

  flink_processor:
    image: flink_processor
    container_name: flink_processor
    restart: unless-stopped
    networks:
      - my-net
    environment:
      SERVICE_PRECONDITION: "kafkabroker:9092 postgres:5432"  


  # superset:
  #   image: superset
  #   container_name: superset
  #   restart: always
  #   environment:
  #     - SUPERSET_LOAD_EXAMPLES=yes
  #     - SUPERSET_SECRET_KEY="some_random_base64_string"
  #   networks:
  #     - my-net
  #   ports:
  #     - "9999:8088"
  
volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
  postgres_data:
  pgdata:
  flink_data:

networks:
  my-net:
    external: true
